{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data from module\n",
    "\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris=load_iris()\n",
    "type(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': 'Iris Plants Database\\n====================\\n\\nNotes\\n-----\\nData Set Characteristics:\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML iris datasets.\\nhttp://archive.ics.uci.edu/ml/datasets/Iris\\n\\nThe famous Iris database, first used by Sir R.A Fisher\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\nReferences\\n----------\\n   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...\\n',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target.shape #expected to  have 1 dimesion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAke deendent variable and independent \n",
    "X=iris.data\n",
    "#y is a vector and X is a matrix\n",
    "y=iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevant class \n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instatntiate the estimator\n",
    "knn=KNeighborsClassifier(n_neighbors=1)\n",
    "#\"knn\" know how to do knn and waiting for us to provide data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "print(knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model with data\n",
    "#model trainingg  step\n",
    "knn.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict([[3, 5, 4, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting for new data set\n",
    "import numpy as np\n",
    "X_new=([[1,2,3,4],[4,5,6,7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model tuning\n",
    "knn=KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "print(knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-knn.predict(X_new)\n",
    "#first array belongs to class 1 (jo bh naam h) and 2nd to other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using a different Classification model\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate model\n",
    "logreg=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit model the data\n",
    "logreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict\n",
    "logreg.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#which model predicts right value??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model evalyuation\n",
    "#train model and test data\n",
    "#logistic first\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg=LogisticRegression()\n",
    "logreg.fit(X, y)\n",
    "y_pred=logreg.predict(X)\n",
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#numerical way to know how our model performed\n",
    "#classfication accuracy- evalauation meteric\n",
    "#metrics model from scikit\n",
    "#training accuracy\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn=5\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=knn.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we will go with knn=1\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn=KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=knn.predict(X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y, y_pred)\n",
    "#knn has memorized training set of data so, always locate nearest neighbor of datpoin itself, so 100% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "#model with high accuracy as above do not go well with predictions\n",
    "#overfiitng; lernt noise, complex model\n",
    "#train test split\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train,y_test=train_test_split(X,y, test_size=0.4, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 4)\n",
      "(60, 4)\n",
      "(90,)\n",
      "(60,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using logistic regression\n",
    "logreg=LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred=logreg.predict(X_test)\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using knn=5\n",
    "knn=KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred=knn.predict(X_test)\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.95,\n",
       " 0.95,\n",
       " 0.9666666666666667,\n",
       " 0.9666666666666667,\n",
       " 0.9666666666666667,\n",
       " 0.9833333333333333,\n",
       " 0.9833333333333333,\n",
       " 0.9833333333333333,\n",
       " 0.9833333333333333,\n",
       " 0.9833333333333333,\n",
       " 0.9833333333333333,\n",
       " 0.9833333333333333,\n",
       " 0.9833333333333333,\n",
       " 0.9833333333333333,\n",
       " 0.9833333333333333,\n",
       " 0.9833333333333333,\n",
       " 0.9833333333333333,\n",
       " 0.9666666666666667,\n",
       " 0.9833333333333333,\n",
       " 0.9666666666666667,\n",
       " 0.9666666666666667,\n",
       " 0.9666666666666667,\n",
       " 0.9666666666666667,\n",
       " 0.95]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Can we use better k\n",
    "#trying values of k from 1 to 25\n",
    "k_range=range(1,25)\n",
    "scores=[]\n",
    "for i in k_range:\n",
    "    knn=KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train,y_train)\n",
    "    y_pred=knn.predict(X_test)\n",
    "    from sklearn import metrics\n",
    "    pred=metrics.accuracy_score(y_test, y_pred)\n",
    "    scores.append(pred)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Accuracy scores')"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the reln b/w value of k and testing accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "#allow plots to appear within notebook\n",
    "%matplotlib inline\n",
    "plt.plot(k_range, scores)\n",
    "plt.xlabel(\"knn values\")\n",
    "plt.ylabel(\"Accuracy scores\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training accuracy rises as model complexity increases. Model complexity is decided by value of k.\n",
    "#testing accuracy penalize model that are too complex as well as those models which are not complex enough\n",
    "#so , k will be best when taken between 6 to 17\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#re-train your model with all available data\n",
    "# train test split is affected due to that\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn=KNeighborsClassifier(n_neighbors=11)\n",
    "knn.fit(X, y)\n",
    "knn.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
